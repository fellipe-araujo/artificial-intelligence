{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/fellipe/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887071\n"
     ]
    }
   ],
   "source": [
    "austen = gutenberg.raw(fileids='austen-emma.txt')\n",
    "\n",
    "sample_text = 'We will discuss briefly about the basic syntax, structure and\\\n",
    "              design philosophies. There is a defined hierarchical syntax for Python code\\\n",
    "              which you should remember when writing code! Python is a really powerful\\\n",
    "              programming language!'\n",
    "\n",
    "print(len(austen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a\n"
     ]
    }
   ],
   "source": [
    "print(austen[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/fellipe/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 3\n",
      "Sample text sentences :-\n",
      "['We will discuss briefly about the basic syntax, structure and              '\n",
      " 'design philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code              which '\n",
      " 'you should remember when writing code!',\n",
      " 'Python is a really powerful              programming language!']\n",
      "\n",
      "Total sentences in austen: 7456\n",
      "First 5 sentences in austen:-\n",
      "['[Emma by Jane Austen 1816]\\n'\n",
      " '\\n'\n",
      " 'VOLUME I\\n'\n",
      " '\\n'\n",
      " 'CHAPTER I\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Emma Woodhouse, handsome, clever, and rich, with a comfortable home\\n'\n",
      " 'and happy disposition, seemed to unite some of the best blessings\\n'\n",
      " 'of existence; and had lived nearly twenty-one years in the world\\n'\n",
      " 'with very little to distress or vex her.',\n",
      " 'She was the youngest of the two daughters of a most affectionate,\\n'\n",
      " \"indulgent father; and had, in consequence of her sister's marriage,\\n\"\n",
      " 'been mistress of his house from a very early period.',\n",
      " 'Her mother\\n'\n",
      " 'had died too long ago for her to have more than an indistinct\\n'\n",
      " 'remembrance of her caresses; and her place had been supplied\\n'\n",
      " 'by an excellent woman as governess, who had fallen little short\\n'\n",
      " 'of a mother in affection.',\n",
      " \"Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\\n\"\n",
      " 'less as a governess than a friend, very fond of both daughters,\\n'\n",
      " 'but particularly of Emma.',\n",
      " 'Between _them_ it was more the intimacy\\nof sisters.']\n"
     ]
    }
   ],
   "source": [
    "default_st = nltk.sent_tokenize\n",
    "austen_sentences = default_st(text=austen)\n",
    "sample_sentences = default_st(text=sample_text)\n",
    "\n",
    "print('Total sentences in sample_text: {}'.format(len(sample_sentences))),\n",
    "print('Sample text sentences :-')\n",
    "pprint(sample_sentences)\n",
    "print('\\nTotal sentences in austen: {}'.format(len(austen_sentences))),\n",
    "print('First 5 sentences in austen:-')\n",
    "pprint(austen_sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package europarl_raw to\n",
      "[nltk_data]     /home/fellipe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/europarl_raw.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('europarl_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in the corpus: 157171\n",
      "First 100 characters in the corpus ->\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sit\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import europarl_raw\n",
    "\n",
    "german_text = europarl_raw.german.raw(fileids='ep-00-01-17.de')\n",
    "\n",
    "print('Total characters in the corpus: {}'.format(len(german_text)))\n",
    "print('First 100 characters in the corpus ->')\n",
    "print(german_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktSentenceTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "german_sentences_def = default_st(text=german_text, language='german')\n",
    "\n",
    "# loading german text tokenizer into a PunktSentenceTokenizer instance\n",
    "german_tokenizer = nltk.data.load(resource_url='tokenizers/punkt/german.pickle')\n",
    "german_sentences = german_tokenizer.tokenize(german_text)\n",
    "\n",
    "# verify the type of german_tokenizer\n",
    "# should be PunktSentenceTokenizer\n",
    "print(type(german_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(german_sentences_def == german_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .\n",
      "Wie Sie feststellen konnten , ist der gefürchtete \" Millenium-Bug \" nicht eingetreten .\n",
      "Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden .\n",
      "Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen .\n",
      "Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen - , allen Opfern der Stürme , insbesondere in den verschiedenen Ländern der Europäischen Union , in einer Schweigeminute zu gedenken .\n"
     ]
    }
   ],
   "source": [
    "# print first 5 sentences of the corpus\n",
    "for sent in german_sentences[0:5]:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We will discuss briefly about the basic syntax, structure and              '\n",
      " 'design philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code              which '\n",
      " 'you should remember when writing code!',\n",
      " 'Python is a really powerful              programming language!']\n"
     ]
    }
   ],
   "source": [
    "punkt_st = nltk.tokenize.PunktSentenceTokenizer()\n",
    "sample_sentences = punkt_st.tokenize(sample_text)\n",
    "pprint(sample_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'was', \"n't\", 'that', 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The brown fox wasn't that quick and he couldn't win the race\"\n",
    "\n",
    "default_wt = nltk.word_tokenize\n",
    "words = default_wt(sentence)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'was', \"n't\", 'that', 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "treebank_wt = nltk.TreebankWordTokenizer()\n",
    "words = treebank_wt.tokenize(sentence)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'wasn', 't', 'that', 'quick', 'and', 'he', 'couldn', 't', 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "# pattern to identify tokens themselves\n",
    "TOKEN_PATTERN = r'\\w+'\n",
    "regex_wt = nltk.RegexpTokenizer(pattern=TOKEN_PATTERN, gaps=False)\n",
    "words = regex_wt.tokenize(sentence)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', \"wasn't\", 'that', 'quick', 'and', 'he', \"couldn't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "# pattern to identify gaps in tokens\n",
    "GAP_PATTERN = r'\\s+'\n",
    "regex_wt = nltk.RegexpTokenizer(pattern=GAP_PATTERN, gaps=True)\n",
    "words = regex_wt.tokenize(sentence)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (4, 9), (10, 13), (14, 20), (21, 25), (26, 31), (32, 35), (36, 38), (39, 47), (48, 51), (52, 55), (56, 60)]\n",
      "['The', 'brown', 'fox', \"wasn't\", 'that', 'quick', 'and', 'he', \"couldn't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "# get start and end indices of each token and then print them\n",
    "word_indices = list(regex_wt.span_tokenize(sentence))\n",
    "\n",
    "print(word_indices)\n",
    "print([sentence[start:end] for start, end in word_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'wasn', \"'\", 't', 'that', 'quick', 'and', 'he', 'couldn', \"'\", 't', 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "wordpunkt_wt = nltk.WordPunctTokenizer()\n",
    "words = wordpunkt_wt.tokenize(sentence)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', \"wasn't\", 'that', 'quick', 'and', 'he', \"couldn't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "whitespace_wt = nltk.WhitespaceTokenizer()\n",
    "words = whitespace_wt.tokenize(sentence)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "  \"The brown fox wasn't that quick and he couldn't win the race\",\\\n",
    "  \"Hey that's a great deal! I just bought a phone for $199\",\\\n",
    "  \"@@You'll (learn) a **lot** in the book. Python is an amazing\\\n",
    "  language !@@\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in textual data, extracts sentences from it, and splits each sentence into further tokens\n",
    "def tokenize_text(text):\n",
    "  sentences = nltk.sent_tokenize(text)\n",
    "  word_tokens = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "  return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The',\n",
      "   'brown',\n",
      "   'fox',\n",
      "   'was',\n",
      "   \"n't\",\n",
      "   'that',\n",
      "   'quick',\n",
      "   'and',\n",
      "   'he',\n",
      "   'could',\n",
      "   \"n't\",\n",
      "   'win',\n",
      "   'the',\n",
      "   'race']],\n",
      " [['Hey', 'that', \"'s\", 'a', 'great', 'deal', '!'],\n",
      "  ['I', 'just', 'bought', 'a', 'phone', 'for', '$', '199']],\n",
      " [['@',\n",
      "   '@',\n",
      "   'You',\n",
      "   \"'ll\",\n",
      "   '(',\n",
      "   'learn',\n",
      "   ')',\n",
      "   'a',\n",
      "   '*',\n",
      "   '*',\n",
      "   'lot',\n",
      "   '*',\n",
      "   '*',\n",
      "   'in',\n",
      "   'the',\n",
      "   'book',\n",
      "   '.'],\n",
      "  ['Python', 'is', 'an', 'amazing', 'language', '!'],\n",
      "  ['@', '@']]]\n"
     ]
    }
   ],
   "source": [
    "token_list = [tokenize_text(text) for text in corpus]\n",
    "\n",
    "pprint(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters_after_tokenization(tokens):\n",
    "  pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "  filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "  return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<filter object at 0x7fad993ebdc0>, <filter object at 0x7fad993ebb50>, <filter object at 0x7fad993eb0a0>]\n"
     ]
    }
   ],
   "source": [
    "filtered_list_1 = [filter(None,[remove_characters_after_tokenization(tokens) for tokens in sentence_tokens]) for sentence_tokens in token_list]\n",
    "\n",
    "print(filtered_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters_before_tokenization(sentence, keep_apostrophes=False):\n",
    "  sentence = sentence.strip()\n",
    "\n",
    "  if keep_apostrophes:\n",
    "    PATTERN = r'[?|$|&|*|%|@|(|)|~]' # add other characters here to remove them\n",
    "    filtered_sentence = re.sub(PATTERN, r'', sentence)\n",
    "  else:\n",
    "    PATTERN = r'[^a-zA-Z0-9 ]' # only extract alpha-numeric characters\n",
    "    filtered_sentence = re.sub(PATTERN, r'', sentence)\n",
    "\n",
    "  return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The brown fox wasnt that quick and he couldnt win the race', 'Hey thats a great deal I just bought a phone for 199', 'Youll learn a lot in the book Python is an amazing  language ']\n"
     ]
    }
   ],
   "source": [
    "filtered_list_2 = [remove_characters_before_tokenization(sentence) for sentence in corpus]\n",
    "\n",
    "print(filtered_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The brown fox wasn't that quick and he couldn't win the race\", \"Hey that's a great deal! I just bought a phone for 199\", \"You'll learn a lot in the book. Python is an amazing  language !\"]\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = [remove_characters_before_tokenization(sentence, keep_apostrophes=True) for sentence in corpus]\n",
    "\n",
    "print(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "  stopword_list = nltk.corpus.stopwords.words('english')\n",
    "  filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "\n",
    "  return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fellipe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The', 'brown', 'fox', \"n't\", 'quick', 'could', \"n't\", 'win', 'race']], [['Hey', \"'s\", 'great', 'deal', '!'], ['I', 'bought', 'phone', '199']], [['You', \"'ll\", 'learn', 'lot', 'book', '.'], ['Python', 'amazing', 'language', '!']]]\n"
     ]
    }
   ],
   "source": [
    "expanded_corpus_tokens = [tokenize_text(text) for text in cleaned_corpus]\n",
    "filtered_list_3 = [[remove_stopwords(tokens) for tokens in sentence_tokens] for sentence_tokens in expanded_corpus_tokens]\n",
    "\n",
    "print(filtered_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords removed\n",
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Repeating Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Step: 4 Word: finaly\n",
      "Final word: finaly\n"
     ]
    }
   ],
   "source": [
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "  # remove one repeated character\n",
    "  new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "\n",
    "  if new_word != old_word:\n",
    "    print('Step: {} Word: {}'.format(step, new_word))\n",
    "    step += 1 # update step\n",
    "\n",
    "    # update old word to last substituted state\n",
    "    old_word = new_word\n",
    "    continue\n",
    "  else:\n",
    "    print('Final word: {}'.format(new_word))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/fellipe/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/fellipe/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Final correct word: finally\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "  # check for semantically correct word\n",
    "  if wordnet.synsets(old_word):\n",
    "    print('Final correct word: {}'.format(old_word))\n",
    "    break\n",
    "\n",
    "  # remove one repeated character\n",
    "  new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "\n",
    "  if new_word != old_word:\n",
    "    print('Step: {} Word: {}'.format(step, new_word))\n",
    "    step += 1 # update step\n",
    "\n",
    "    # update old word to last substituted state\n",
    "    old_word = new_word\n",
    "    continue\n",
    "  else:\n",
    "    print('Final word: {}'.format(new_word))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def remove_repeated_characters(tokens):\n",
    "  repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "  match_substitution = r'\\1\\2\\3'\n",
    "\n",
    "  def replace(old_word):\n",
    "    if wordnet.synsets(old_word):\n",
    "      return old_word\n",
    "\n",
    "    new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "\n",
    "    return replace(new_word) if new_word != old_word else new_word\n",
    "\n",
    "  correct_tokens = [replace(word) for word in tokens]\n",
    "\n",
    "  return correct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'schooool', 'is', 'realllllyyy', 'amaaazingggg']\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = 'My schooool is realllllyyy amaaazingggg'\n",
    "sample_sentence_tokens = tokenize_text(sample_sentence)[0]\n",
    "\n",
    "print(sample_sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'school', 'is', 'really', 'amazing']\n"
     ]
    }
   ],
   "source": [
    "print(remove_repeated_characters(sample_sentence_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections\n",
    "\n",
    "def tokens(text):\n",
    "  \"\"\"\n",
    "  Get all words from the corpus\n",
    "  \"\"\"\n",
    "  return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "f = open('big_text.txt', 'r')\n",
    "\n",
    "WORDS = tokens(f.read())\n",
    "WORD_COUNTS = collections.Counter(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 80030), ('of', 40025), ('and', 38313), ('to', 28766), ('in', 22050), ('a', 21155), ('that', 12512), ('he', 12401), ('was', 11410), ('it', 10681)]\n"
     ]
    }
   ],
   "source": [
    "# top 10 words in the corpus\n",
    "print(WORD_COUNTS.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits0(word):\n",
    "  \"\"\"\n",
    "  Return all strings that are zero edits away\n",
    "  from the input word (i.e., the word itself).\n",
    "  \"\"\"\n",
    "  return {word}\n",
    "\n",
    "def edits1(word):\n",
    "  \"\"\"\n",
    "  Return all strings that are one edit away\n",
    "  from the input word.\n",
    "  \"\"\"\n",
    "  alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "  def splits(word):\n",
    "    \"\"\"\n",
    "    Return a list of all possible (first, rest) pairs\n",
    "    that the input word is made of.\n",
    "    \"\"\"\n",
    "    return [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "  \n",
    "  pairs = splits(word)\n",
    "  deletes = [a+b[1:] for (a, b) in pairs if b]\n",
    "  transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "  replaces = [a+c+b[1:] for (a, b) in pairs for c in alphabet if b]\n",
    "  inserts = [a+c+b for (a, b) in pairs for c in alphabet]\n",
    "\n",
    "  return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "  \"\"\"Return all strings that are two edits away\n",
    "  from the input word.\n",
    "  \"\"\"\n",
    "  return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "  \"\"\"\n",
    "  Return the subset of words that are actually\n",
    "  in our WORD_COUNTS dictionary.\n",
    "  \"\"\"\n",
    "  return {w for w in words if w in WORD_COUNTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlly'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input word\n",
    "word = 'fianlly'\n",
    "\n",
    "# zero edit distance from input word\n",
    "edits0(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns null set since it is not a valid word\n",
    "known(edits0(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afianlly',\n",
       " 'aianlly',\n",
       " 'bfianlly',\n",
       " 'bianlly',\n",
       " 'cfianlly',\n",
       " 'cianlly',\n",
       " 'dfianlly',\n",
       " 'dianlly',\n",
       " 'efianlly',\n",
       " 'eianlly',\n",
       " 'faanlly',\n",
       " 'faianlly',\n",
       " 'fainlly',\n",
       " 'fanlly',\n",
       " 'fbanlly',\n",
       " 'fbianlly',\n",
       " 'fcanlly',\n",
       " 'fcianlly',\n",
       " 'fdanlly',\n",
       " 'fdianlly',\n",
       " 'feanlly',\n",
       " 'feianlly',\n",
       " 'ffanlly',\n",
       " 'ffianlly',\n",
       " 'fganlly',\n",
       " 'fgianlly',\n",
       " 'fhanlly',\n",
       " 'fhianlly',\n",
       " 'fiaally',\n",
       " 'fiaanlly',\n",
       " 'fiablly',\n",
       " 'fiabnlly',\n",
       " 'fiaclly',\n",
       " 'fiacnlly',\n",
       " 'fiadlly',\n",
       " 'fiadnlly',\n",
       " 'fiaelly',\n",
       " 'fiaenlly',\n",
       " 'fiaflly',\n",
       " 'fiafnlly',\n",
       " 'fiaglly',\n",
       " 'fiagnlly',\n",
       " 'fiahlly',\n",
       " 'fiahnlly',\n",
       " 'fiailly',\n",
       " 'fiainlly',\n",
       " 'fiajlly',\n",
       " 'fiajnlly',\n",
       " 'fiaklly',\n",
       " 'fiaknlly',\n",
       " 'fiallly',\n",
       " 'fially',\n",
       " 'fialnlly',\n",
       " 'fialnly',\n",
       " 'fiamlly',\n",
       " 'fiamnlly',\n",
       " 'fianally',\n",
       " 'fianaly',\n",
       " 'fianblly',\n",
       " 'fianbly',\n",
       " 'fianclly',\n",
       " 'fiancly',\n",
       " 'fiandlly',\n",
       " 'fiandly',\n",
       " 'fianelly',\n",
       " 'fianely',\n",
       " 'fianflly',\n",
       " 'fianfly',\n",
       " 'fianglly',\n",
       " 'fiangly',\n",
       " 'fianhlly',\n",
       " 'fianhly',\n",
       " 'fianilly',\n",
       " 'fianily',\n",
       " 'fianjlly',\n",
       " 'fianjly',\n",
       " 'fianklly',\n",
       " 'fiankly',\n",
       " 'fianlaly',\n",
       " 'fianlay',\n",
       " 'fianlbly',\n",
       " 'fianlby',\n",
       " 'fianlcly',\n",
       " 'fianlcy',\n",
       " 'fianldly',\n",
       " 'fianldy',\n",
       " 'fianlely',\n",
       " 'fianley',\n",
       " 'fianlfly',\n",
       " 'fianlfy',\n",
       " 'fianlgly',\n",
       " 'fianlgy',\n",
       " 'fianlhly',\n",
       " 'fianlhy',\n",
       " 'fianlily',\n",
       " 'fianliy',\n",
       " 'fianljly',\n",
       " 'fianljy',\n",
       " 'fianlkly',\n",
       " 'fianlky',\n",
       " 'fianll',\n",
       " 'fianlla',\n",
       " 'fianllay',\n",
       " 'fianllb',\n",
       " 'fianllby',\n",
       " 'fianllc',\n",
       " 'fianllcy',\n",
       " 'fianlld',\n",
       " 'fianlldy',\n",
       " 'fianlle',\n",
       " 'fianlley',\n",
       " 'fianllf',\n",
       " 'fianllfy',\n",
       " 'fianllg',\n",
       " 'fianllgy',\n",
       " 'fianllh',\n",
       " 'fianllhy',\n",
       " 'fianlli',\n",
       " 'fianlliy',\n",
       " 'fianllj',\n",
       " 'fianlljy',\n",
       " 'fianllk',\n",
       " 'fianllky',\n",
       " 'fianlll',\n",
       " 'fianllly',\n",
       " 'fianllm',\n",
       " 'fianllmy',\n",
       " 'fianlln',\n",
       " 'fianllny',\n",
       " 'fianllo',\n",
       " 'fianlloy',\n",
       " 'fianllp',\n",
       " 'fianllpy',\n",
       " 'fianllq',\n",
       " 'fianllqy',\n",
       " 'fianllr',\n",
       " 'fianllry',\n",
       " 'fianlls',\n",
       " 'fianllsy',\n",
       " 'fianllt',\n",
       " 'fianllty',\n",
       " 'fianllu',\n",
       " 'fianlluy',\n",
       " 'fianllv',\n",
       " 'fianllvy',\n",
       " 'fianllw',\n",
       " 'fianllwy',\n",
       " 'fianllx',\n",
       " 'fianllxy',\n",
       " 'fianlly',\n",
       " 'fianllya',\n",
       " 'fianllyb',\n",
       " 'fianllyc',\n",
       " 'fianllyd',\n",
       " 'fianllye',\n",
       " 'fianllyf',\n",
       " 'fianllyg',\n",
       " 'fianllyh',\n",
       " 'fianllyi',\n",
       " 'fianllyj',\n",
       " 'fianllyk',\n",
       " 'fianllyl',\n",
       " 'fianllym',\n",
       " 'fianllyn',\n",
       " 'fianllyo',\n",
       " 'fianllyp',\n",
       " 'fianllyq',\n",
       " 'fianllyr',\n",
       " 'fianllys',\n",
       " 'fianllyt',\n",
       " 'fianllyu',\n",
       " 'fianllyv',\n",
       " 'fianllyw',\n",
       " 'fianllyx',\n",
       " 'fianllyy',\n",
       " 'fianllyz',\n",
       " 'fianllz',\n",
       " 'fianllzy',\n",
       " 'fianlmly',\n",
       " 'fianlmy',\n",
       " 'fianlnly',\n",
       " 'fianlny',\n",
       " 'fianloly',\n",
       " 'fianloy',\n",
       " 'fianlply',\n",
       " 'fianlpy',\n",
       " 'fianlqly',\n",
       " 'fianlqy',\n",
       " 'fianlrly',\n",
       " 'fianlry',\n",
       " 'fianlsly',\n",
       " 'fianlsy',\n",
       " 'fianltly',\n",
       " 'fianlty',\n",
       " 'fianluly',\n",
       " 'fianluy',\n",
       " 'fianlvly',\n",
       " 'fianlvy',\n",
       " 'fianlwly',\n",
       " 'fianlwy',\n",
       " 'fianlxly',\n",
       " 'fianlxy',\n",
       " 'fianly',\n",
       " 'fianlyl',\n",
       " 'fianlyly',\n",
       " 'fianlyy',\n",
       " 'fianlzly',\n",
       " 'fianlzy',\n",
       " 'fianmlly',\n",
       " 'fianmly',\n",
       " 'fiannlly',\n",
       " 'fiannly',\n",
       " 'fianolly',\n",
       " 'fianoly',\n",
       " 'fianplly',\n",
       " 'fianply',\n",
       " 'fianqlly',\n",
       " 'fianqly',\n",
       " 'fianrlly',\n",
       " 'fianrly',\n",
       " 'fianslly',\n",
       " 'fiansly',\n",
       " 'fiantlly',\n",
       " 'fiantly',\n",
       " 'fianully',\n",
       " 'fianuly',\n",
       " 'fianvlly',\n",
       " 'fianvly',\n",
       " 'fianwlly',\n",
       " 'fianwly',\n",
       " 'fianxlly',\n",
       " 'fianxly',\n",
       " 'fianylly',\n",
       " 'fianyly',\n",
       " 'fianzlly',\n",
       " 'fianzly',\n",
       " 'fiaolly',\n",
       " 'fiaonlly',\n",
       " 'fiaplly',\n",
       " 'fiapnlly',\n",
       " 'fiaqlly',\n",
       " 'fiaqnlly',\n",
       " 'fiarlly',\n",
       " 'fiarnlly',\n",
       " 'fiaslly',\n",
       " 'fiasnlly',\n",
       " 'fiatlly',\n",
       " 'fiatnlly',\n",
       " 'fiaully',\n",
       " 'fiaunlly',\n",
       " 'fiavlly',\n",
       " 'fiavnlly',\n",
       " 'fiawlly',\n",
       " 'fiawnlly',\n",
       " 'fiaxlly',\n",
       " 'fiaxnlly',\n",
       " 'fiaylly',\n",
       " 'fiaynlly',\n",
       " 'fiazlly',\n",
       " 'fiaznlly',\n",
       " 'fibanlly',\n",
       " 'fibnlly',\n",
       " 'ficanlly',\n",
       " 'ficnlly',\n",
       " 'fidanlly',\n",
       " 'fidnlly',\n",
       " 'fieanlly',\n",
       " 'fienlly',\n",
       " 'fifanlly',\n",
       " 'fifnlly',\n",
       " 'figanlly',\n",
       " 'fignlly',\n",
       " 'fihanlly',\n",
       " 'fihnlly',\n",
       " 'fiianlly',\n",
       " 'fiinlly',\n",
       " 'fijanlly',\n",
       " 'fijnlly',\n",
       " 'fikanlly',\n",
       " 'fiknlly',\n",
       " 'filanlly',\n",
       " 'filnlly',\n",
       " 'fimanlly',\n",
       " 'fimnlly',\n",
       " 'finally',\n",
       " 'finanlly',\n",
       " 'finlly',\n",
       " 'finnlly',\n",
       " 'fioanlly',\n",
       " 'fionlly',\n",
       " 'fipanlly',\n",
       " 'fipnlly',\n",
       " 'fiqanlly',\n",
       " 'fiqnlly',\n",
       " 'firanlly',\n",
       " 'firnlly',\n",
       " 'fisanlly',\n",
       " 'fisnlly',\n",
       " 'fitanlly',\n",
       " 'fitnlly',\n",
       " 'fiuanlly',\n",
       " 'fiunlly',\n",
       " 'fivanlly',\n",
       " 'fivnlly',\n",
       " 'fiwanlly',\n",
       " 'fiwnlly',\n",
       " 'fixanlly',\n",
       " 'fixnlly',\n",
       " 'fiyanlly',\n",
       " 'fiynlly',\n",
       " 'fizanlly',\n",
       " 'fiznlly',\n",
       " 'fjanlly',\n",
       " 'fjianlly',\n",
       " 'fkanlly',\n",
       " 'fkianlly',\n",
       " 'flanlly',\n",
       " 'flianlly',\n",
       " 'fmanlly',\n",
       " 'fmianlly',\n",
       " 'fnanlly',\n",
       " 'fnianlly',\n",
       " 'foanlly',\n",
       " 'foianlly',\n",
       " 'fpanlly',\n",
       " 'fpianlly',\n",
       " 'fqanlly',\n",
       " 'fqianlly',\n",
       " 'franlly',\n",
       " 'frianlly',\n",
       " 'fsanlly',\n",
       " 'fsianlly',\n",
       " 'ftanlly',\n",
       " 'ftianlly',\n",
       " 'fuanlly',\n",
       " 'fuianlly',\n",
       " 'fvanlly',\n",
       " 'fvianlly',\n",
       " 'fwanlly',\n",
       " 'fwianlly',\n",
       " 'fxanlly',\n",
       " 'fxianlly',\n",
       " 'fyanlly',\n",
       " 'fyianlly',\n",
       " 'fzanlly',\n",
       " 'fzianlly',\n",
       " 'gfianlly',\n",
       " 'gianlly',\n",
       " 'hfianlly',\n",
       " 'hianlly',\n",
       " 'ianlly',\n",
       " 'ifanlly',\n",
       " 'ifianlly',\n",
       " 'iianlly',\n",
       " 'jfianlly',\n",
       " 'jianlly',\n",
       " 'kfianlly',\n",
       " 'kianlly',\n",
       " 'lfianlly',\n",
       " 'lianlly',\n",
       " 'mfianlly',\n",
       " 'mianlly',\n",
       " 'nfianlly',\n",
       " 'nianlly',\n",
       " 'ofianlly',\n",
       " 'oianlly',\n",
       " 'pfianlly',\n",
       " 'pianlly',\n",
       " 'qfianlly',\n",
       " 'qianlly',\n",
       " 'rfianlly',\n",
       " 'rianlly',\n",
       " 'sfianlly',\n",
       " 'sianlly',\n",
       " 'tfianlly',\n",
       " 'tianlly',\n",
       " 'ufianlly',\n",
       " 'uianlly',\n",
       " 'vfianlly',\n",
       " 'vianlly',\n",
       " 'wfianlly',\n",
       " 'wianlly',\n",
       " 'xfianlly',\n",
       " 'xianlly',\n",
       " 'yfianlly',\n",
       " 'yianlly',\n",
       " 'zfianlly',\n",
       " 'zianlly'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one edit distance from input word\n",
    "edits1(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cfianmlly',\n",
       " 'fjazlly',\n",
       " 'fianlhll',\n",
       " 'rfiaflly',\n",
       " 'fianlfll',\n",
       " 'fianwlg',\n",
       " 'xfianfly',\n",
       " 'fianllei',\n",
       " 'fiacnllly',\n",
       " 'faiablly',\n",
       " 'fianslle',\n",
       " 'fianlblyd',\n",
       " 'fianyllb',\n",
       " 'sfianlyy',\n",
       " 'fibnllg',\n",
       " 'frianlyly',\n",
       " 'fiankaly',\n",
       " 'fidmanlly',\n",
       " 'fnianqly',\n",
       " 'fifanllyh',\n",
       " 'xianllyy',\n",
       " 'fiarnllye',\n",
       " 'fiaqnley',\n",
       " 'fianolnly',\n",
       " 'hlfianlly',\n",
       " 'sianlty',\n",
       " 'fiavolly',\n",
       " 'fianzoy',\n",
       " 'finnllh',\n",
       " 'fimanhly',\n",
       " 'fianylliy',\n",
       " 'gfiaolly',\n",
       " 'fsanlmly',\n",
       " 'fiadnloly',\n",
       " 'fijanlay',\n",
       " 'fianlvjy',\n",
       " 'fjanlgly',\n",
       " 'afisnlly',\n",
       " 'fzanilly',\n",
       " 'fiaxnllxy',\n",
       " 'fiannll',\n",
       " 'feianlsly',\n",
       " 'flmnlly',\n",
       " 'fqianllhy',\n",
       " 'ffanloy',\n",
       " 'fuannlly',\n",
       " 'yianllz',\n",
       " 'fzicanlly',\n",
       " 'fifankly',\n",
       " 'faianlny',\n",
       " 'frianlvly',\n",
       " 'fikanfly',\n",
       " 'fikuanlly',\n",
       " 'cfianllp',\n",
       " 'lijnlly',\n",
       " 'fianllybh',\n",
       " 'afianplly',\n",
       " 'fziangly',\n",
       " 'tianllx',\n",
       " 'fiqanlqly',\n",
       " 'fiarnsly',\n",
       " 'fianevlly',\n",
       " 'fianxxlly',\n",
       " 'fiamley',\n",
       " 'fdanoly',\n",
       " 'fiaawlly',\n",
       " 'fivnllmy',\n",
       " 'fikanllyb',\n",
       " 'cfianblly',\n",
       " 'gfianlily',\n",
       " 'fxianllyv',\n",
       " 'fianlaily',\n",
       " 'fibanlaly',\n",
       " 'ffantlly',\n",
       " 'jianlaly',\n",
       " 'finnll',\n",
       " 'ftiaolly',\n",
       " 'ifianilly',\n",
       " 'fiakllp',\n",
       " 'tfianlkly',\n",
       " 'fianyvlly',\n",
       " 'fiiqlly',\n",
       " 'fiaollc',\n",
       " 'fnanlly',\n",
       " 'fianlwd',\n",
       " 'fianplyr',\n",
       " 'fizsnlly',\n",
       " 'finanllyo',\n",
       " 'fxinanlly',\n",
       " 'jfianllyw',\n",
       " 'fianllxyv',\n",
       " 'mganlly',\n",
       " 'fvanlfly',\n",
       " 'fianlcym',\n",
       " 'fiunloly',\n",
       " 'fiawnslly',\n",
       " 'fianlkky',\n",
       " 'fyianllpy',\n",
       " 'fqanlls',\n",
       " 'fkanzlly',\n",
       " 'fcanllyn',\n",
       " 'fmanllyq',\n",
       " 'fialnelly',\n",
       " 'fifnly',\n",
       " 'fpianlyl',\n",
       " 'fiangqlly',\n",
       " 'cfiaonlly',\n",
       " 'fixanllzy',\n",
       " 'fiamjnlly',\n",
       " 'ciannly',\n",
       " 'ecanlly',\n",
       " 'fwanglly',\n",
       " 'fiallfly',\n",
       " 'fignllyz',\n",
       " 'fjiaqlly',\n",
       " 'fiasnlljy',\n",
       " 'fivnmly',\n",
       " 'fianlgsy',\n",
       " 'fdaqnlly',\n",
       " 'fianlvby',\n",
       " 'fiajllym',\n",
       " 'fqanlwly',\n",
       " 'fiaonlnly',\n",
       " 'fiallyl',\n",
       " 'fianmyy',\n",
       " 'fiatllqy',\n",
       " 'fnanally',\n",
       " 'fianlgm',\n",
       " 'ifaxnlly',\n",
       " 'mfianqly',\n",
       " 'fincnlly',\n",
       " 'fianplys',\n",
       " 'jicnlly',\n",
       " 'fianlwy',\n",
       " 'tianuly',\n",
       " 'fiahllya',\n",
       " 'fganllyt',\n",
       " 'fiacnlsy',\n",
       " 'fiianllyh',\n",
       " 'xmfianlly',\n",
       " 'fianlelyr',\n",
       " 'jfrianlly',\n",
       " 'fianwllyq',\n",
       " 'fianllymk',\n",
       " 'fbianllyi',\n",
       " 'fihoanlly',\n",
       " 'fiarnllyo',\n",
       " 'fdianlyy',\n",
       " 'fianzglly',\n",
       " 'fnanllyx',\n",
       " 'fziaenlly',\n",
       " 'fdanllcy',\n",
       " 'gfiknlly',\n",
       " 'hfianllyl',\n",
       " 'fiacrnlly',\n",
       " 'fiantlyz',\n",
       " 'fianpllk',\n",
       " 'lianlvly',\n",
       " 'fiablls',\n",
       " 'fikawnlly',\n",
       " 'ficnrlly',\n",
       " 'xitanlly',\n",
       " 'iianllyx',\n",
       " 'aianllyh',\n",
       " 'fsanlzly',\n",
       " 'avfianlly',\n",
       " 'faanlloy',\n",
       " 'fianloyz',\n",
       " 'oianllyp',\n",
       " 'wfiannlly',\n",
       " 'qidanlly',\n",
       " 'fianlvlyl',\n",
       " 'wfianlby',\n",
       " 'fiancllyf',\n",
       " 'fiaenljy',\n",
       " 'fiaonlyly',\n",
       " 'hfiaynlly',\n",
       " 'fitnwlly',\n",
       " 'yianlvly',\n",
       " 'fianllyua',\n",
       " 'fnianllyw',\n",
       " 'fiidlly',\n",
       " 'fianljty',\n",
       " 'fiagnllyp',\n",
       " 'fjanllmy',\n",
       " 'aianlqly',\n",
       " 'fitanlwly',\n",
       " 'gfianllyk',\n",
       " 'ftaznlly',\n",
       " 'fianeloly',\n",
       " 'frianllj',\n",
       " 'fiansnly',\n",
       " 'fianllyod',\n",
       " 'fiqanllym',\n",
       " 'fitnllm',\n",
       " 'fietanlly',\n",
       " 'fiaznllcy',\n",
       " 'fienllyx',\n",
       " 'ifwianlly',\n",
       " 'hidanlly',\n",
       " 'fianlxlyq',\n",
       " 'fianllcq',\n",
       " 'fifanllys',\n",
       " 'fianlolym',\n",
       " 'wiaqlly',\n",
       " 'afiablly',\n",
       " 'fiahlqly',\n",
       " 'aianluy',\n",
       " 'dihanlly',\n",
       " 'fhiannlly',\n",
       " 'fianllgym',\n",
       " 'fmanlhly',\n",
       " 'fiewlly',\n",
       " 'fiallbly',\n",
       " 'fianllyaz',\n",
       " 'fianlvlo',\n",
       " 'filanlwy',\n",
       " 'fianllbyi',\n",
       " 'fiafnldy',\n",
       " 'dfianelly',\n",
       " 'faianllyf',\n",
       " 'fiafllqy',\n",
       " 'fiwnylly',\n",
       " 'fianavy',\n",
       " 'fiacnllpy',\n",
       " 'fikncly',\n",
       " 'fianxllly',\n",
       " 'fioanllyq',\n",
       " 'flianluy',\n",
       " 'gianlld',\n",
       " 'qfianrly',\n",
       " 'fianluzly',\n",
       " 'fianlliyv',\n",
       " 'wqianlly',\n",
       " 'fhaully',\n",
       " 'fxankly',\n",
       " 'fikanlley',\n",
       " 'fianlylhy',\n",
       " 'fiaollty',\n",
       " 'fganily',\n",
       " 'fiamwly',\n",
       " 'fanxlly',\n",
       " 'fianlludy',\n",
       " 'fmanlley',\n",
       " 'ficnllv',\n",
       " 'finallzy',\n",
       " 'fiarnllcy',\n",
       " 'piazlly',\n",
       " 'fianhlx',\n",
       " 'fianlltyf',\n",
       " 'firaflly',\n",
       " 'fianollmy',\n",
       " 'bfijnlly',\n",
       " 'fhianllb',\n",
       " 'fnalnlly',\n",
       " 'qianqlly',\n",
       " 'fianlelqy',\n",
       " 'fanllby',\n",
       " 'fianljlhy',\n",
       " 'fyiailly',\n",
       " 'fiaknly',\n",
       " 'bdianlly',\n",
       " 'fcanily',\n",
       " 'fiaqtlly',\n",
       " 'fiatllhy',\n",
       " 'fixandly',\n",
       " 'fiwalnlly',\n",
       " 'fjiasnlly',\n",
       " 'fianllqy',\n",
       " 'fianblf',\n",
       " 'fianllmry',\n",
       " 'fianallyj',\n",
       " 'fianxlyr',\n",
       " 'finamlly',\n",
       " 'fiagnlln',\n",
       " 'fiaqllx',\n",
       " 'fianlglvy',\n",
       " 'jianyly',\n",
       " 'wfianlily',\n",
       " 'fmiaylly',\n",
       " 'rffianlly',\n",
       " 'fianjlby',\n",
       " 'fiunhly',\n",
       " 'fmaplly',\n",
       " 'fuialnly',\n",
       " 'fiaanly',\n",
       " 'fisslly',\n",
       " 'fbiahlly',\n",
       " 'fivanrlly',\n",
       " 'ziantly',\n",
       " 'fihnrly',\n",
       " 'fiianllc',\n",
       " 'fiuaxlly',\n",
       " 'crfianlly',\n",
       " 'fliahlly',\n",
       " 'xianllye',\n",
       " 'ficanzlly',\n",
       " 'uianllb',\n",
       " 'iirnlly',\n",
       " 'fvnianlly',\n",
       " 'fmanllyh',\n",
       " 'fxznlly',\n",
       " 'figanldly',\n",
       " 'fmanllm',\n",
       " 'efianldy',\n",
       " 'fiaqully',\n",
       " 'fianlliyi',\n",
       " 'fyieanlly',\n",
       " 'fiyaslly',\n",
       " 'fcanfly',\n",
       " 'fiamnfly',\n",
       " 'fzanlljy',\n",
       " 'fiaanllwy',\n",
       " 'riazlly',\n",
       " 'fdaianlly',\n",
       " 'fiaallt',\n",
       " 'fiahljly',\n",
       " 'fyianluy',\n",
       " 'fyanllyu',\n",
       " 'oiahnlly',\n",
       " 'fipahlly',\n",
       " 'fiwanllyl',\n",
       " 'fianoxlly',\n",
       " 'fuianllyk',\n",
       " 'fvanwlly',\n",
       " 'lianllx',\n",
       " 'xaanlly',\n",
       " 'fianwlvy',\n",
       " 'fimfanlly',\n",
       " 'fianlhay',\n",
       " 'fianlwlyc',\n",
       " 'frpanlly',\n",
       " 'frianyly',\n",
       " 'fuianzlly',\n",
       " 'fiaullmy',\n",
       " 'fianllyfg',\n",
       " 'cfiawlly',\n",
       " 'fikaxlly',\n",
       " 'cainlly',\n",
       " 'fidanlxy',\n",
       " 'fianyllyy',\n",
       " 'yfiamlly',\n",
       " 'fiabnlbly',\n",
       " 'fiwanlay',\n",
       " 'fisanllyw',\n",
       " 'fijxanlly',\n",
       " 'fianllbyr',\n",
       " 'fwanllyb',\n",
       " 'fibanllzy',\n",
       " 'fxanllr',\n",
       " 'fianlleby',\n",
       " 'fiadnlfly',\n",
       " 'fialnlyc',\n",
       " 'fzanjlly',\n",
       " 'fianliliy',\n",
       " 'fianllyzy',\n",
       " 'fizaxlly',\n",
       " 'imfianlly',\n",
       " 'yianrlly',\n",
       " 'filanlpy',\n",
       " 'wianxlly',\n",
       " 'dianlhy',\n",
       " 'flialnlly',\n",
       " 'fiknllyc',\n",
       " 'qfianaly',\n",
       " 'fiafdly',\n",
       " 'iikanlly',\n",
       " 'bfianvly',\n",
       " 'cfiafnlly',\n",
       " 'fiaxnlgy',\n",
       " 'fianlmhly',\n",
       " 'feinanlly',\n",
       " 'fixnlluy',\n",
       " 'gfianllyp',\n",
       " 'fianlzj',\n",
       " 'fivnlhly',\n",
       " 'fiaudly',\n",
       " 'fiaznloy',\n",
       " 'fianllyzs',\n",
       " 'fianlluh',\n",
       " 'fpanflly',\n",
       " 'fianity',\n",
       " 'aianvly',\n",
       " 'ffalnly',\n",
       " 'fiqanslly',\n",
       " 'fianlflyi',\n",
       " 'fianldyo',\n",
       " 'fianudly',\n",
       " 'fiodanlly',\n",
       " 'efiacnlly',\n",
       " 'fuanllyn',\n",
       " 'fianhllqy',\n",
       " 'eilnlly',\n",
       " 'fignqlly',\n",
       " 'fdally',\n",
       " 'kfiaenlly',\n",
       " 'kfianllmy',\n",
       " 'fianplyb',\n",
       " 'yfianqlly',\n",
       " 'fianrhly',\n",
       " 'fialnjly',\n",
       " 'fhanljy',\n",
       " 'fiafhly',\n",
       " 'jfiinlly',\n",
       " 'efiknlly',\n",
       " 'figknlly',\n",
       " 'fiaotlly',\n",
       " 'ufianely',\n",
       " 'fxanlwy',\n",
       " 'filnllz',\n",
       " 'fiamntly',\n",
       " 'ufilnlly',\n",
       " 'mfiaxlly',\n",
       " 'fiaynoly',\n",
       " 'fuiaylly',\n",
       " 'cfianllyy',\n",
       " 'fbianlay',\n",
       " 'kialnly',\n",
       " 'fianlvp',\n",
       " 'cianllya',\n",
       " 'fwianlily',\n",
       " 'qianzlly',\n",
       " 'fiqjlly',\n",
       " 'fkanllz',\n",
       " 'ftanlfy',\n",
       " 'fbanaly',\n",
       " 'fianvltly',\n",
       " 'fianlzlyv',\n",
       " 'fiaallpy',\n",
       " 'biadnlly',\n",
       " 'fianllgh',\n",
       " 'cianhly',\n",
       " 'fihzanlly',\n",
       " 'fianllkt',\n",
       " 'friainlly',\n",
       " 'fiaylkly',\n",
       " 'fianllocy',\n",
       " 'xianclly',\n",
       " 'fihnltly',\n",
       " 'fiatnllqy',\n",
       " 'fiaplle',\n",
       " 'fianilny',\n",
       " 'fignklly',\n",
       " 'cfsianlly',\n",
       " 'fiaklln',\n",
       " 'ftanlely',\n",
       " 'filnaly',\n",
       " 'fianclljy',\n",
       " 'fiargnlly',\n",
       " 'fiahllmy',\n",
       " 'fiavinlly',\n",
       " 'fsaknlly',\n",
       " 'fitanlxy',\n",
       " 'fianwllvy',\n",
       " 'fianctlly',\n",
       " 'fiaplliy',\n",
       " 'fpanqlly',\n",
       " 'fiaonllfy',\n",
       " 'firpnlly',\n",
       " 'fsanlvly',\n",
       " 'franlay',\n",
       " 'ffianyly',\n",
       " 'findlly',\n",
       " 'fiaulli',\n",
       " 'giaxlly',\n",
       " 'fiynxly',\n",
       " 'fxawnlly',\n",
       " 'fianqllj',\n",
       " 'ifianlyly',\n",
       " 'fiahnllyq',\n",
       " 'fiaynplly',\n",
       " 'fiaenluy',\n",
       " 'fidajnlly',\n",
       " 'fzanllye',\n",
       " 'fganlly',\n",
       " 'fvynlly',\n",
       " 'feianlxly',\n",
       " 'fiexlly',\n",
       " 'fianllvq',\n",
       " 'fianzllya',\n",
       " 'fzanluly',\n",
       " 'hianslly',\n",
       " 'fiaplldy',\n",
       " 'fianflvly',\n",
       " 'fianlwlcy',\n",
       " 'kfianllyk',\n",
       " 'fianllypi',\n",
       " 'pfianjlly',\n",
       " 'fiandlye',\n",
       " 'fianllpyj',\n",
       " 'fiuzanlly',\n",
       " 'fianluyg',\n",
       " 'bisnlly',\n",
       " 'vfianlpy',\n",
       " 'fzalnly',\n",
       " 'fianslya',\n",
       " 'hfianlli',\n",
       " 'fdablly',\n",
       " 'frianllu',\n",
       " 'tianlley',\n",
       " 'fgianllyv',\n",
       " 'ifianlay',\n",
       " 'finanluly',\n",
       " 'wiaglly',\n",
       " 'fxirnlly',\n",
       " 'fanllu',\n",
       " 'friaflly',\n",
       " 'yfiunlly',\n",
       " 'fijwanlly',\n",
       " 'fitnllyp',\n",
       " 'fiannlwy',\n",
       " 'fiaxnbly',\n",
       " 'fiaqlloy',\n",
       " 'fianlmzly',\n",
       " 'ffaianlly',\n",
       " 'fianllypw',\n",
       " 'fiasnlny',\n",
       " 'fianlcyg',\n",
       " 'ficantlly',\n",
       " 'fiavnllm',\n",
       " 'fiwnlxy',\n",
       " 'faanflly',\n",
       " 'fmanllyo',\n",
       " 'fhipnlly',\n",
       " 'piaxnlly',\n",
       " 'fisznlly',\n",
       " 'fiaqlley',\n",
       " 'fianyuy',\n",
       " 'biaznlly',\n",
       " 'flaynlly',\n",
       " 'fianglyl',\n",
       " 'fialnloly',\n",
       " 'ianllfy',\n",
       " 'fiaelvy',\n",
       " 'fwanllm',\n",
       " 'fianlilg',\n",
       " 'ftanwly',\n",
       " 'fiahklly',\n",
       " 'fiatnelly',\n",
       " 'fwianllk',\n",
       " 'tfwanlly',\n",
       " 'fyailly',\n",
       " 'ofinlly',\n",
       " 'tfkianlly',\n",
       " 'qmianlly',\n",
       " 'fzianllg',\n",
       " 'nfianrlly',\n",
       " 'gjanlly',\n",
       " 'fianlljpy',\n",
       " 'ftjianlly',\n",
       " 'fnanllyk',\n",
       " 'fiwanclly',\n",
       " 'ffally',\n",
       " 'fiailty',\n",
       " 'fianzlld',\n",
       " 'fjianlry',\n",
       " 'fifklly',\n",
       " 'fidanlxly',\n",
       " 'faahlly',\n",
       " 'jfianllyz',\n",
       " 'fialnjy',\n",
       " 'foianljy',\n",
       " 'fiaknilly',\n",
       " 'fnianlply',\n",
       " 'fianallyp',\n",
       " 'fignllhy',\n",
       " 'fiqnlny',\n",
       " 'cfioanlly',\n",
       " 'fiinlely',\n",
       " 'fiaucly',\n",
       " 'qufianlly',\n",
       " 'fiwlnlly',\n",
       " 'fiavnily',\n",
       " 'fmianllx',\n",
       " 'fixnllc',\n",
       " 'fianlslty',\n",
       " 'fiwnllyf',\n",
       " 'fiuanllyx',\n",
       " 'rianlaly',\n",
       " 'fianlco',\n",
       " 'foianlhy',\n",
       " 'frianllmy',\n",
       " 'fiahkly',\n",
       " 'fianuvlly',\n",
       " 'fianlels',\n",
       " 'fitaylly',\n",
       " 'xfiahnlly',\n",
       " 'fiianll',\n",
       " 'fianlqyly',\n",
       " 'fianlzya',\n",
       " 'fianllkyu',\n",
       " 'fiaomly',\n",
       " 'tiatlly',\n",
       " 'fijanlloy',\n",
       " 'fiaahly',\n",
       " 'fianlsls',\n",
       " 'fianllpsy',\n",
       " 'fcianlny',\n",
       " 'ficrnlly',\n",
       " 'fiainllye',\n",
       " 'fiatlqly',\n",
       " 'fihnllfy',\n",
       " 'fibanll',\n",
       " 'lihanlly',\n",
       " 'fianxkly',\n",
       " 'fdaslly',\n",
       " 'fijnnlly',\n",
       " 'fianllcyt',\n",
       " 'foianll',\n",
       " 'fviavnlly',\n",
       " 'fianrwlly',\n",
       " 'fianllsyj',\n",
       " 'vfiunlly',\n",
       " 'ftanbly',\n",
       " 'fianolzly',\n",
       " 'fianiply',\n",
       " 'fiarllyp',\n",
       " 'fiqlnly',\n",
       " 'fifanllhy',\n",
       " 'fsiyanlly',\n",
       " 'fxanllg',\n",
       " 'cianll',\n",
       " 'ofianllsy',\n",
       " 'giajnlly',\n",
       " 'fqidanlly',\n",
       " 'fianflliy',\n",
       " 'fignvlly',\n",
       " 'fhznlly',\n",
       " 'fjanllyl',\n",
       " 'efilanlly',\n",
       " 'fianllhfy',\n",
       " 'fuizanlly',\n",
       " 'fiamnllyv',\n",
       " 'ofianely',\n",
       " 'fianlfily',\n",
       " 'fganljy',\n",
       " 'fihmanlly',\n",
       " 'efiinlly',\n",
       " 'xiaynlly',\n",
       " 'fviancly',\n",
       " 'fianillyo',\n",
       " 'pfianlfly',\n",
       " 'fzanllny',\n",
       " 'qnfianlly',\n",
       " 'fianhlyw',\n",
       " 'fdganlly',\n",
       " 'foanllyw',\n",
       " 'feivnlly',\n",
       " 'vianlxly',\n",
       " 'fjaunlly',\n",
       " 'fianlllq',\n",
       " 'fianylr',\n",
       " 'fiaplay',\n",
       " 'fyannlly',\n",
       " 'fiaenllj',\n",
       " 'irianlly',\n",
       " 'fifnllvy',\n",
       " 'fvonlly',\n",
       " 'fiabily',\n",
       " 'qeanlly',\n",
       " 'fianliyp',\n",
       " 'fianollr',\n",
       " 'fianlsiy',\n",
       " 'fiapkly',\n",
       " 'ptfianlly',\n",
       " 'ifanllfy',\n",
       " 'ffyianlly',\n",
       " 'efianmly',\n",
       " 'fianflyu',\n",
       " 'fignlfy',\n",
       " 'fianllhpy',\n",
       " 'ciwanlly',\n",
       " 'fianlclmy',\n",
       " 'fizablly',\n",
       " 'finlnlly',\n",
       " 'fiaytly',\n",
       " 'fgiqanlly',\n",
       " 'pfianmly',\n",
       " 'fianlclry',\n",
       " 'fipjanlly',\n",
       " 'fianllxym',\n",
       " 'wfiaknlly',\n",
       " 'fiaxllyl',\n",
       " 'fianllymh',\n",
       " 'nianply',\n",
       " 'fcianyly',\n",
       " 'fanllry',\n",
       " 'kfianllfy',\n",
       " 'gfianlyly',\n",
       " 'risnlly',\n",
       " 'foazlly',\n",
       " 'fianallqy',\n",
       " 'fijnlay',\n",
       " 'fianwlfy',\n",
       " 'fiankny',\n",
       " 'wianllyh',\n",
       " 'fiaondly',\n",
       " 'fioaqlly',\n",
       " 'fiaplzy',\n",
       " 'fiagncly',\n",
       " 'fjanlyl',\n",
       " 'fiaznlby',\n",
       " 'fiacllty',\n",
       " 'kfimanlly',\n",
       " 'fainlrly',\n",
       " 'nfiantly',\n",
       " 'sfiaglly',\n",
       " 'fiqnllyq',\n",
       " 'fcxanlly',\n",
       " 'fidcnlly',\n",
       " 'fkiawnlly',\n",
       " 'fwitanlly',\n",
       " 'fianlelay',\n",
       " 'fiamnlzy',\n",
       " 'yfianluly',\n",
       " 'fanllr',\n",
       " 'fivhnlly',\n",
       " 'aiaklly',\n",
       " 'fiadlli',\n",
       " 'fziaslly',\n",
       " 'fiacnhly',\n",
       " 'tbanlly',\n",
       " 'fianlleay',\n",
       " 'fianllggy',\n",
       " 'fdianlli',\n",
       " 'vianely',\n",
       " 'fiuanlrly',\n",
       " 'cfianlyly',\n",
       " 'fianlfxly',\n",
       " 'fialnlyb',\n",
       " 'fnanllyn',\n",
       " 'cignlly',\n",
       " 'ianllr',\n",
       " 'fkatlly',\n",
       " 'fiznllp',\n",
       " 'hfianllyb',\n",
       " 'fpianldy',\n",
       " 'fidnllyl',\n",
       " 'fianxay',\n",
       " 'fdqnlly',\n",
       " 'fainmly',\n",
       " 'diajlly',\n",
       " 'fianxolly',\n",
       " 'fioanlkly',\n",
       " 'fialnnlly',\n",
       " 'fianlldp',\n",
       " 'fianlolyc',\n",
       " 'fiasnolly',\n",
       " 'exfianlly',\n",
       " 'fvaianlly',\n",
       " 'fianllery',\n",
       " 'fiaqllb',\n",
       " 'nfianlmy',\n",
       " 'yfianlli',\n",
       " 'gianllyr',\n",
       " 'ftanllgy',\n",
       " 'fbianlxly',\n",
       " 'flibnlly',\n",
       " 'fianllgyg',\n",
       " 'fianlltl',\n",
       " 'fdianilly',\n",
       " 'fianplay',\n",
       " 'fgajlly',\n",
       " 'rfiahlly',\n",
       " 'fpially',\n",
       " 'fiwanlyly',\n",
       " 'fianglt',\n",
       " 'fimnltly',\n",
       " 'fianllhgy',\n",
       " 'rvfianlly',\n",
       " 'fiandlloy',\n",
       " 'fximanlly',\n",
       " 'fmanlln',\n",
       " 'fialnlmy',\n",
       " 'fiacllg',\n",
       " 'fiantla',\n",
       " 'fianllezy',\n",
       " 'fbanlsly',\n",
       " 'fbiantly',\n",
       " 'fimjanlly',\n",
       " 'fanllz',\n",
       " 'pfianlln',\n",
       " 'fianlvily',\n",
       " 'fijanjlly',\n",
       " 'fiaellgy',\n",
       " 'fijawlly',\n",
       " 'firnllo',\n",
       " 'fieaylly',\n",
       " 'fiabllyt',\n",
       " 'himnlly',\n",
       " 'efanlly',\n",
       " 'fiaqfly',\n",
       " 'fiaflll',\n",
       " 'pifnlly',\n",
       " 'siaknlly',\n",
       " 'hfianluly',\n",
       " 'fianlm',\n",
       " 'fianilxy',\n",
       " 'fitnlty',\n",
       " 'sfianllyk',\n",
       " 'jianllg',\n",
       " 'fiayllqy',\n",
       " 'fianglys',\n",
       " 'fifnlsy',\n",
       " 'fianllnyw',\n",
       " 'fiahvly',\n",
       " 'fuianllt',\n",
       " 'fiainylly',\n",
       " 'fimatlly',\n",
       " 'fiaunllyw',\n",
       " 'miaxlly',\n",
       " 'sfhanlly',\n",
       " 'fioanley',\n",
       " 'jfiandlly',\n",
       " 'fsanlzy',\n",
       " 'fianlelh',\n",
       " 'fiianvlly',\n",
       " 'hfkianlly',\n",
       " 'fianljyw',\n",
       " 'fikanklly',\n",
       " 'qxianlly',\n",
       " 'fdaplly',\n",
       " 'fidhanlly',\n",
       " 'fiaullcy',\n",
       " 'fiabdly',\n",
       " 'flnanlly',\n",
       " 'jiqnlly',\n",
       " 'fvangly',\n",
       " 'fwxanlly',\n",
       " 'afiynlly',\n",
       " 'fiakllyn',\n",
       " 'fianllryz',\n",
       " 'fianuilly',\n",
       " 'gfiansly',\n",
       " 'fiarnluly',\n",
       " 'fiaplluy',\n",
       " 'fiavnlfy',\n",
       " 'fpiznlly',\n",
       " 'uianluy',\n",
       " 'fiynllyx',\n",
       " 'fiadnlay',\n",
       " 'fyianlny',\n",
       " 'feianllyc',\n",
       " 'fianloyu',\n",
       " 'etfianlly',\n",
       " 'fianylyo',\n",
       " 'flianlby',\n",
       " 'firnlfy',\n",
       " 'fiarvlly',\n",
       " 'fifflly',\n",
       " 'fiandlyc',\n",
       " 'fiajllzy',\n",
       " 'yfianlhy',\n",
       " 'foianlluy',\n",
       " 'figanley',\n",
       " 'fiaklrly',\n",
       " 'fidylly',\n",
       " 'fjiamlly',\n",
       " 'fianllxly',\n",
       " 'yvfianlly',\n",
       " 'fiabnldly',\n",
       " 'frnnlly',\n",
       " 'fiapncly',\n",
       " 'fijknlly',\n",
       " 'bfibanlly',\n",
       " 'fiatily',\n",
       " 'hyanlly',\n",
       " 'fianllsyb',\n",
       " 'fiamqnlly',\n",
       " 'fiyanlxy',\n",
       " 'fxianllyq',\n",
       " 'bianllpy',\n",
       " 'fianglyn',\n",
       " 'fiavnqly',\n",
       " 'fiianlll',\n",
       " 'fioaknlly',\n",
       " 'fianlloyv',\n",
       " 'fiakllys',\n",
       " 'fgilnlly',\n",
       " 'fiandllmy',\n",
       " 'fisnllyq',\n",
       " 'tfnianlly',\n",
       " 'fialnlo',\n",
       " 'jfiaelly',\n",
       " 'fiajnslly',\n",
       " 'fyfanlly',\n",
       " 'fpanlpy',\n",
       " 'fiahnlyy',\n",
       " 'ifianelly',\n",
       " 'fiapnllt',\n",
       " 'wianldy',\n",
       " 'fianbally',\n",
       " 'kilanlly',\n",
       " 'fcanllf',\n",
       " 'hiwnlly',\n",
       " 'fxanlljy',\n",
       " 'fianzld',\n",
       " 'fiabnllo',\n",
       " 'foinanlly',\n",
       " 'ifianally',\n",
       " 'cianwlly',\n",
       " 'foianllyd',\n",
       " 'fkanfly',\n",
       " 'fianllot',\n",
       " 'fivnllyo',\n",
       " 'yianlaly',\n",
       " 'ifenlly',\n",
       " 'yfiaally',\n",
       " 'fdanlfly',\n",
       " 'fiazllvy',\n",
       " 'fiajnldly',\n",
       " 'ifzanlly',\n",
       " 'fxalnly',\n",
       " 'frianluly',\n",
       " 'fiallyg',\n",
       " 'fianllhyi',\n",
       " 'yfianllyp',\n",
       " 'fiapnhly',\n",
       " 'frianlzly',\n",
       " 'rfinnlly',\n",
       " 'cianllby',\n",
       " 'fiahnll',\n",
       " 'firnlby',\n",
       " 'hzianlly',\n",
       " 'finlli',\n",
       " 'xdfianlly',\n",
       " 'fainully',\n",
       " 'uiaully',\n",
       " 'fxianllyg',\n",
       " 'fhanllqy',\n",
       " 'fiznllye',\n",
       " 'fianlblmy',\n",
       " 'foanlely',\n",
       " 'jkfianlly',\n",
       " 'fnianllyt',\n",
       " 'oufianlly',\n",
       " 'gfianloly',\n",
       " 'fxcanlly',\n",
       " 'fianrllc',\n",
       " 'ffianqlly',\n",
       " 'eiagnlly',\n",
       " 'finlqy',\n",
       " 'fiaxllwy',\n",
       " 'fimhnlly',\n",
       " 'fiasnllzy',\n",
       " 'fianmlgy',\n",
       " 'ndianlly',\n",
       " 'nfianluly',\n",
       " 'fiandkly',\n",
       " 'zianllyu',\n",
       " 'fianfgy',\n",
       " 'fwianlry',\n",
       " 'rianllyk',\n",
       " 'rbanlly',\n",
       " 'fiinllz',\n",
       " 'fianllyhx',\n",
       " 'fiadnlliy',\n",
       " 'fiaintly',\n",
       " 'ffanllyt',\n",
       " 'fianlrwy',\n",
       " 'fiznlfy',\n",
       " 'firanllyq',\n",
       " 'fianlljq',\n",
       " 'fianlvjly',\n",
       " 'niaelly',\n",
       " 'eianllv',\n",
       " 'fiaxnliy',\n",
       " 'fiatlla',\n",
       " 'afianlvy',\n",
       " 'zfaianlly',\n",
       " 'fvanllyh',\n",
       " 'fvdnlly',\n",
       " 'gianllky',\n",
       " 'fnianllq',\n",
       " 'vfihanlly',\n",
       " 'nofianlly',\n",
       " 'fdanjly',\n",
       " 'fianlzu',\n",
       " 'fianglc',\n",
       " 'fiaynlldy',\n",
       " 'fiaualy',\n",
       " 'fiarnllyi',\n",
       " 'fiadnlqly',\n",
       " 'fzanllys',\n",
       " 'lianlley',\n",
       " 'fkqianlly',\n",
       " 'fyianblly',\n",
       " 'nianhly',\n",
       " 'fiafliy',\n",
       " 'finllcy',\n",
       " 'fibnhlly',\n",
       " 'fiaypnlly',\n",
       " 'fiazlly',\n",
       " 'fqqanlly',\n",
       " 'fixuanlly',\n",
       " 'fiangvlly',\n",
       " 'oganlly',\n",
       " 'fiuanllu',\n",
       " 'fianplaly',\n",
       " 'fignllzy',\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faintly', 'finally', 'finely', 'frankly'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits2(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = (known(edits0(word)) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "  \"\"\"\n",
    "  Get the best correct spelling for the input word\n",
    "  \"\"\"\n",
    "  # Priority is for edit distance 0, then 1, then 2\n",
    "  # else defaults to the input word itself.\n",
    "  candidates = (known(edits0(word)) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "  return max(candidates, key=WORD_COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FIANLLY'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_match(match):\n",
    "  \"\"\"\n",
    "  Spell-correct word in match,\n",
    "  and preserve proper upper/lower/title case.\n",
    "  \"\"\"\n",
    "  word = match.group()\n",
    "\n",
    "  def case_of(text):\n",
    "    \"\"\"\n",
    "    Return the case-function appropriate\n",
    "    for text: upper, lower, title, or just str.:\n",
    "    \"\"\"\n",
    "    return (str.upper if text.isupper() else str.lower if text.islower() else str.title if text.istitle() else str)\n",
    "\n",
    "  return case_of(word)(correct(word.lower()))\n",
    "\n",
    "def correct_text_generic(text):\n",
    "  \"\"\"\n",
    "  Correct all the words within a text,\n",
    "  returning the corrected text.\n",
    "  \"\"\"\n",
    "  return re.sub('[a-zA-Z]+', correct_match, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINALLY'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('FIANLLY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump jump jump\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lie\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('lying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strang\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('strange'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump jump jump\n"
     ]
    }
   ],
   "source": [
    "print(ls.stem('jumping'), ls.stem('jumps'), ls.stem('jumped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lying\n"
     ]
    }
   ],
   "source": [
    "print(ls.stem('lying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strange\n"
     ]
    }
   ],
   "source": [
    "print(ls.stem('strange'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex based stemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "rs = RegexpStemmer('ing$|s$|ed$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump jump jump\n"
     ]
    }
   ],
   "source": [
    "print(rs.stem('jumping'), rs.stem('jumps'), rs.stem('jumped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ly\n"
     ]
    }
   ],
   "source": [
    "print(rs.stem('lying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strange\n"
     ]
    }
   ],
   "source": [
    "print(rs.stem('strange'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "men\n"
     ]
    }
   ],
   "source": [
    "# lemmatize nouns\n",
    "print(wnl.lemmatize('cars', 'n'))\n",
    "print(wnl.lemmatize('men', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# lemmatize verbs\n",
    "print(wnl.lemmatize('running', 'v'))\n",
    "print(wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "# lemmatize adjectives\n",
    "print(wnl.lemmatize('saddest', 'a'))\n",
    "print(wnl.lemmatize('fancier', 'a'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
